{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnipC4z3_hEl"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvz7XIYa_hEu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cs2pJSFj_hFB"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7FwcraT_hFF"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNJWAnV__hFj"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V4EpNgPd_hFv"
   },
   "source": [
    "##### <font color='red'> Path to train and test csv's => how to submit?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsxKcmrR_hF2"
   },
   "outputs": [],
   "source": [
    "# train_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/train.csv').readlines())\n",
    "# val_doc = np.random.permutation(open('/notebooks/storage/Final_data/Collated_training/val.csv').readlines())\n",
    "\n",
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzTpzfzd_hGj"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(image):\n",
    "    epsilon = 1e-7\n",
    "    norm_image = (image - image.mean(axis=(0,1,2), keepdims=True)) / image.std(axis=(0,1,2), keepdims=True)\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm2(image):\n",
    "    return np.array((image - np.min(image)) / (np.max(image) - np.min(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm3(image):\n",
    "    return (image - np.percentile(image,5)) / (np.percentile(image,95) - np.percentile(image,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZPP4BKIB_hHK"
   },
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, image_idx,img_dim,image_norm_method=1 ):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    # img_idx = #create a list of image numbers you want to use for a particular video\n",
    "    img_idx = image_idx\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list) // batch_size\n",
    "        \n",
    "        # for remaining videos\n",
    "        remaining_sequences = len(folder_list) % batch_size\n",
    "#         print(\"batch_size = \" , batch_size, \" and sequences = \" , remaining_sequences)\n",
    "        x = len(img_idx)\n",
    "        y = img_dim[0]\n",
    "        z = img_dim[1]        \n",
    "        \n",
    "        for batch in range(num_batches): # we iterate over the number of batches   \n",
    "#             print(\"current batch = \", batch)\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            \n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    if(image.shape[0]!=image.shape[1]):\n",
    "                        image=image[0:120,20:140]\n",
    "                    \n",
    "                    # `imresize` is deprecated!\n",
    "                    # `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
    "                    # Use ``skimage.transform.resize`` instead.\n",
    "                    image = imresize(image, (y,z))\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    # after normalization, the values will be converted to float, is that fine?\n",
    "                    if image_norm_method==1:\n",
    "                        norm_image = norm1(image)\n",
    "                    elif image_norm_method ==2:\n",
    "                        norm_image = norm2(image)\n",
    "                    else:\n",
    "                        norm_image = norm3(image)\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = norm_image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = norm_image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = norm_image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "#         print(\"processing remaining sequences = \" ,remaining_sequences, \"::num_batches=\", num_batches)\n",
    "        if remaining_sequences != 0:\n",
    "            batch_size = remaining_sequences\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (num_batches*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (num_batches*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    if(image.shape[0]!=image.shape[1]):\n",
    "                        image=image[0:120,20:140]\n",
    "                    image = imresize(image, (y,z))\n",
    "                    \n",
    "                    if image_norm_method==1:\n",
    "                        norm_image = norm1(image)\n",
    "                    else:\n",
    "                        norm_image = norm2(image)\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = norm_image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = norm_image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = norm_image[:,:,2]\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                \n",
    "                yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdoLFUjM_hHa"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDdEBylo_hIH",
    "outputId": "79fb93e8-c136-4a47-fc2b-74e38b653006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "# train_path = '/notebooks/storage/Final_data/Collated_training/train'\n",
    "# val_path = '/notebooks/storage/Final_data/Collated_training/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZdzz8PT_hIR"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g37xS4K2_hIT"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "#write your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uklqgquv_hIi"
   },
   "source": [
    "## 3d CNN models\n",
    "\n",
    "- https://ieeexplore.ieee.org/document/8545718 (later experiment with more conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scT1i1mx_hIm"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, filters, optimiser=Adam()):\n",
    "\n",
    "    filter_size = filters\n",
    "    # filter_size = [8,16,32,64,128,256]\n",
    "    dense_layer_size = [256,128] #256,256\n",
    "\n",
    "#     input_shape=(len(image_idx),image_width,image_height,3)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    #Layer 1\n",
    "    model.add(Conv3D(filters=filter_size[0],kernel_size=(3,3,3),input_shape=input_shape, padding='same')) # 'valid'\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "    #Layer 2\n",
    "    model.add(Conv3D(filters=filter_size[1],kernel_size=(3,3,3), padding='same')) # 'valid'\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "    #Layer 3\n",
    "    model.add(Conv3D(filters=filter_size[2],kernel_size=(1,3,3), padding='same')) # 'valid'\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # #Layer 4\n",
    "    model.add(Conv3D(filters=filter_size[3],kernel_size=(1,3,3), padding='same')) # 'valid'\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense 1\n",
    "    model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Dense 2\n",
    "    model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # final softmax\n",
    "    #softmax layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DijCHJtI_hI2"
   },
   "source": [
    "### Convolutions + RNN\n",
    "- The conv2D network will extract a feature vector for each image, and a sequence of these feature vectors is then fed to an RNN-based network. The output of the RNN is a regular softmax (for a classification problem such as this one).\n",
    "\n",
    "#### There are a few key things to note about the conv-RNN architecture:\n",
    "\n",
    "- You can use transfer learning in the 2D CNN layer rather than training your own CNN \n",
    "- GRU can be a better choice than an LSTM since it has lesser number of gates (and thus parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCsFMjoN_hI5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTfW8ro1_hJA"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5mt_jC5_hJC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sgEZj0xq_hJO",
    "outputId": "e13e8d0b-2cb4-460c-f8db-dc7b66622b5c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimiser = Adam()\n",
    "# model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtqpcSAq_hGo"
   },
   "source": [
    "### <font color='green'>TODO - select the list of image indexes from the video\n",
    "- take +/-7 images from the mid position </font>\n",
    "\n",
    "### <font color='green'>TODO - num_batches formula \n",
    "    \n",
    "- x = len(img_idx)\n",
    "- y = height of image\n",
    "- z = width of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkDsGWCv_hGt"
   },
   "outputs": [],
   "source": [
    "# image_width = 100\n",
    "# image_height = 100\n",
    "# # image_idx = list(np.arange(0,30,2))\n",
    "# image_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
    "# print(len(image_idx))\n",
    "\n",
    "# batch_size = 8\n",
    "\n",
    "# num_epochs = 20 #50\n",
    "# print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ih4mzNo_hJT"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKP3aaMC_hJZ"
   },
   "outputs": [],
   "source": [
    "def create_train_val_generators(batch_size, image_idx,img_dim, image_norm_method=1):\n",
    "    train_path = './Project_data/train'\n",
    "    val_path = './Project_data/val'\n",
    "\n",
    "    train_generator = generator(train_path, train_doc, batch_size, image_idx,img_dim,image_norm_method=image_norm_method)\n",
    "    val_generator = generator(val_path, val_doc, batch_size, image_idx, img_dim,image_norm_method=image_norm_method)\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9VyYTHg_hJk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGt-fNJt_hJt"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_int_model(model, train_generator, val_generator,batch_size, num_epochs, model_log):\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "        \n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + model_log +'/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "\n",
    "    filepath = model_name + 'model_-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "    #early stopping required\n",
    "    ES = EarlyStopping(monitor='val_loss', verbose=1, patience=5)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, \n",
    "                                 save_weights_only=False, mode='auto', period=1)\n",
    "    # patience can be increased with early stopping (5)\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, cooldown=1, verbose=1)\n",
    "    # callbacks_list = [checkpoint, LR, ES]\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "    \n",
    "    \n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUedP8Kg_hJv"
   },
   "outputs": [],
   "source": [
    "def train_model(epoch, batch_size, img_norm_method, log, optimizer=Adam(), filters = [16,32,64,128]):\n",
    "    \n",
    "    image_width = 100\n",
    "    image_height = 100\n",
    "    \n",
    "    image_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
    "\n",
    "    batch_size = batch_size\n",
    "    num_epochs = epoch\n",
    "    img_dim = (image_height,image_width)\n",
    "    train_gen, val_gen = create_train_val_generators(batch_size=batch_size,image_idx=image_idx,img_dim=img_dim,image_norm_method=img_norm_method)\n",
    "    \n",
    "    # length of video sequence, width, height, num_channels\n",
    "    input_shape=(len(image_idx), image_width, image_height, 3)\n",
    "    \n",
    "    model = create_model(input_shape=input_shape, filters=filters, optimiser=optimizer)\n",
    "    \n",
    "    train_int_model(model = model, train_generator=train_gen, val_generator=val_gen, batch_size=batch_size,num_epochs=epoch,model_log=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 8\n",
      "Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 1s - loss: 3.8308 - categorical_accuracy: 0.2180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 136s 2s/step - loss: 3.7883 - categorical_accuracy: 0.2171 - val_loss: 1.4953 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00001-3.79349-0.21719-1.49534-0.23000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 38s 457ms/step - loss: 1.6470 - categorical_accuracy: 0.2134 - val_loss: 1.6122 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00002-1.64701-0.21343-1.61220-0.25000.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 32s 385ms/step - loss: 1.6113 - categorical_accuracy: 0.2506 - val_loss: 1.5254 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00003-1.61386-0.24944-1.52540-0.36538.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 29s 345ms/step - loss: 1.6011 - categorical_accuracy: 0.1927 - val_loss: 1.6073 - val_categorical_accuracy: 0.1731\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00004-1.60786-0.18926-1.60733-0.17308.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 18s 222ms/step - loss: 1.5751 - categorical_accuracy: 0.2249 - val_loss: 1.5439 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00005-1.57514-0.22490-1.54387-0.38462.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 19s 229ms/step - loss: 1.6075 - categorical_accuracy: 0.2289 - val_loss: 1.5900 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00006-1.60748-0.22892-1.59004-0.28846.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 19s 230ms/step - loss: 1.5841 - categorical_accuracy: 0.2731 - val_loss: 1.5355 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00007-1.58413-0.27309-1.53550-0.28846.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 1.5985 - categorical_accuracy: 0.2369 - val_loss: 1.5710 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00008-1.59847-0.23695-1.57103-0.32692.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 1.6102 - categorical_accuracy: 0.2570 - val_loss: 1.5586 - val_categorical_accuracy: 0.2115\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00009-1.61024-0.25703-1.55857-0.21154.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 1.6108 - categorical_accuracy: 0.2088 - val_loss: 1.6025 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00010-1.61084-0.20884-1.60247-0.23077.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 19s 226ms/step - loss: 1.5985 - categorical_accuracy: 0.2289 - val_loss: 1.6207 - val_categorical_accuracy: 0.1731\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00011-1.59846-0.22892-1.62066-0.17308.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 20s 237ms/step - loss: 1.5876 - categorical_accuracy: 0.2249 - val_loss: 1.5957 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00012-1.58764-0.22490-1.59572-0.28846.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 1.5459 - categorical_accuracy: 0.2450 - val_loss: 1.4579 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00013-1.54593-0.24498-1.45788-0.36538.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 19s 234ms/step - loss: 1.5269 - categorical_accuracy: 0.3012 - val_loss: 1.4489 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00014-1.52689-0.30120-1.44885-0.46154.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 20s 236ms/step - loss: 1.6102 - categorical_accuracy: 0.2209 - val_loss: 1.5479 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00015-1.61021-0.22088-1.54795-0.26923.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 19s 226ms/step - loss: 1.5949 - categorical_accuracy: 0.2329 - val_loss: 1.5317 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00016-1.59488-0.23293-1.53172-0.32692.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 19s 231ms/step - loss: 1.5465 - categorical_accuracy: 0.2530 - val_loss: 1.4284 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00017-1.54648-0.25301-1.42836-0.36538.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 19s 223ms/step - loss: 1.4806 - categorical_accuracy: 0.2851 - val_loss: 1.4273 - val_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00018-1.48058-0.28514-1.42730-0.42308.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 19s 231ms/step - loss: 1.5696 - categorical_accuracy: 0.2329 - val_loss: 1.3067 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00019-1.56959-0.23293-1.30672-0.38462.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 1.4912 - categorical_accuracy: 0.3373 - val_loss: 1.4042 - val_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582norm_1/model_-00020-1.49122-0.33735-1.40424-0.42308.h5\n",
      "1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"1\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=1, log=\"norm_1\",filters = [16,32,64,128])\n",
    "print(\"1\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_13 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_16 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path = Source path =  ./Project_data/train ; batch size =  8\n",
      "./Project_data/val ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 0s - loss: 7.4043 - categorical_accuracy: 0.2439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 49s 593ms/step - loss: 7.3152 - categorical_accuracy: 0.2461 - val_loss: 10.4916 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00001-7.32613-0.24585-10.49157-0.20000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 37s 443ms/step - loss: 2.5560 - categorical_accuracy: 0.2651 - val_loss: 2.6808 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00002-2.55598-0.26506-2.68083-0.38462.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 30s 361ms/step - loss: 1.6562 - categorical_accuracy: 0.2572 - val_loss: 1.4939 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00003-1.65356-0.26058-1.49386-0.30769.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 27s 322ms/step - loss: 1.5890 - categorical_accuracy: 0.2578 - val_loss: 1.4884 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00004-1.59576-0.25320-1.48837-0.28846.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 19s 224ms/step - loss: 1.6024 - categorical_accuracy: 0.2811 - val_loss: 1.4390 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00005-1.60239-0.28112-1.43904-0.38462.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 1.6092 - categorical_accuracy: 0.2088 - val_loss: 1.5231 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00006-1.60923-0.20884-1.52314-0.26923.h5\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 17s 206ms/step - loss: 1.5724 - categorical_accuracy: 0.2771 - val_loss: 1.4758 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00007-1.57236-0.27711-1.47582-0.40385.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 1.5510 - categorical_accuracy: 0.2651 - val_loss: 1.4804 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00008-1.55097-0.26506-1.48041-0.34615.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 1.5317 - categorical_accuracy: 0.2651 - val_loss: 1.4736 - val_categorical_accuracy: 0.2115\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00009-1.53175-0.26506-1.47362-0.21154.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 1.5016 - categorical_accuracy: 0.3414 - val_loss: 1.4411 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00010-1.50163-0.34137-1.44111-0.34615.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 18s 212ms/step - loss: 1.5807 - categorical_accuracy: 0.3133 - val_loss: 1.4289 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00011-1.58075-0.31325-1.42892-0.34615.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 1.4806 - categorical_accuracy: 0.3454 - val_loss: 1.3032 - val_categorical_accuracy: 0.4423\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00012-1.48063-0.34538-1.30324-0.44231.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 1.5341 - categorical_accuracy: 0.3052 - val_loss: 1.3398 - val_categorical_accuracy: 0.4423\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00013-1.53411-0.30522-1.33977-0.44231.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 18s 212ms/step - loss: 1.4831 - categorical_accuracy: 0.3695 - val_loss: 1.3097 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00014-1.48313-0.36948-1.30973-0.34615.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 1.4631 - categorical_accuracy: 0.3494 - val_loss: 1.2758 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00015-1.46305-0.34940-1.27577-0.50000.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 17s 209ms/step - loss: 1.4431 - categorical_accuracy: 0.3735 - val_loss: 1.2219 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00016-1.44310-0.37349-1.22191-0.40385.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 1.4483 - categorical_accuracy: 0.3373 - val_loss: 1.2462 - val_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00017-1.44830-0.33735-1.24616-0.42308.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 19s 227ms/step - loss: 1.4285 - categorical_accuracy: 0.3614 - val_loss: 1.2206 - val_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00018-1.42848-0.36145-1.22057-0.42308.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 17s 199ms/step - loss: 1.4068 - categorical_accuracy: 0.3695 - val_loss: 1.2916 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00019-1.40681-0.36948-1.29165-0.40385.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 1.4079 - categorical_accuracy: 0.4257 - val_loss: 1.1681 - val_categorical_accuracy: 0.4808\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582norm_2/model_-00020-1.40787-0.42570-1.16808-0.48077.h5\n",
      "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"2\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=2,log=\"norm_2\",filters = [16,32,64,128])\n",
    "print(\"2\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_17 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 8\n",
      "Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 0s - loss: 3.4021 - categorical_accuracy: 0.2210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 56s 674ms/step - loss: 3.3651 - categorical_accuracy: 0.2184 - val_loss: 1.5356 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00001-3.36962-0.21870-1.53555-0.30000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 42s 506ms/step - loss: 1.6121 - categorical_accuracy: 0.2599 - val_loss: 1.5931 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00002-1.61208-0.25990-1.59312-0.23077.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 35s 418ms/step - loss: 1.6139 - categorical_accuracy: 0.2018 - val_loss: 1.6046 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00003-1.61223-0.20490-1.60461-0.25000.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 31s 373ms/step - loss: 1.5637 - categorical_accuracy: 0.2867 - val_loss: 1.6069 - val_categorical_accuracy: 0.1346\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00004-1.57491-0.28389-1.60695-0.13462.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 20s 239ms/step - loss: 1.6102 - categorical_accuracy: 0.2249 - val_loss: 1.5889 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00005-1.61016-0.22490-1.58887-0.25000.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 22s 260ms/step - loss: 1.6063 - categorical_accuracy: 0.2932 - val_loss: 1.5713 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00006-1.60628-0.29317-1.57127-0.30769.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 22s 260ms/step - loss: 1.5769 - categorical_accuracy: 0.2811 - val_loss: 1.5578 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00007-1.57691-0.28112-1.55781-0.28846.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 20s 246ms/step - loss: 1.5479 - categorical_accuracy: 0.3414 - val_loss: 1.5529 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00008-1.54795-0.34137-1.55291-0.38462.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 1.5701 - categorical_accuracy: 0.3012 - val_loss: 1.5417 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00009-1.57013-0.30120-1.54170-0.34615.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 20s 241ms/step - loss: 1.5856 - categorical_accuracy: 0.2972 - val_loss: 1.5242 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00010-1.58559-0.29719-1.52419-0.36538.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 1.5132 - categorical_accuracy: 0.3454 - val_loss: 1.5269 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00011-1.51316-0.34538-1.52693-0.40385.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 20s 244ms/step - loss: 1.5716 - categorical_accuracy: 0.2329 - val_loss: 1.5327 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00012-1.57165-0.23293-1.53268-0.36538.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 21s 258ms/step - loss: 1.5031 - categorical_accuracy: 0.3133 - val_loss: 1.4596 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00013-1.50308-0.31325-1.45956-0.36538.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 20s 243ms/step - loss: 1.5186 - categorical_accuracy: 0.3052 - val_loss: 1.4800 - val_categorical_accuracy: 0.5192\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00014-1.51855-0.30522-1.47996-0.51923.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 21s 248ms/step - loss: 1.5016 - categorical_accuracy: 0.3494 - val_loss: 1.4257 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00015-1.50161-0.34940-1.42569-0.34615.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 21s 256ms/step - loss: 1.5597 - categorical_accuracy: 0.3213 - val_loss: 1.4466 - val_categorical_accuracy: 0.4231\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00016-1.55973-0.32129-1.44660-0.42308.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 20s 245ms/step - loss: 1.5202 - categorical_accuracy: 0.3133 - val_loss: 1.4845 - val_categorical_accuracy: 0.4808\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00017-1.52021-0.31325-1.48447-0.48077.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 21s 252ms/step - loss: 1.5015 - categorical_accuracy: 0.3373 - val_loss: 1.4693 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00018-1.50155-0.33735-1.46929-0.38462.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 21s 259ms/step - loss: 1.4679 - categorical_accuracy: 0.3735 - val_loss: 1.3561 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00019-1.46792-0.37349-1.35613-0.46154.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 21s 255ms/step - loss: 1.5181 - categorical_accuracy: 0.3775 - val_loss: 1.4127 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582norm_3/model_-00020-1.51805-0.37751-1.41273-0.50000.h5\n",
      "3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"3\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=3,log=\"norm_3\",filters = [16,32,64,128])\n",
    "print(\"3\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After checking which is normalization method check the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_21 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 8\n",
      "Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 0s - loss: 2.7323 - categorical_accuracy: 0.2027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 48s 581ms/step - loss: 2.7046 - categorical_accuracy: 0.2020 - val_loss: 1.3577 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00001-2.70795-0.20211-1.35767-0.37000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 35s 425ms/step - loss: 1.6793 - categorical_accuracy: 0.2599 - val_loss: 1.5387 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00002-1.67932-0.25990-1.53867-0.30769.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 29s 347ms/step - loss: 1.4853 - categorical_accuracy: 0.3118 - val_loss: 1.3911 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00003-1.49174-0.30735-1.39113-0.40385.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 26s 312ms/step - loss: 1.6348 - categorical_accuracy: 0.2771 - val_loss: 1.4387 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00004-1.63666-0.27877-1.43866-0.36538.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 1.5525 - categorical_accuracy: 0.2771 - val_loss: 1.3592 - val_categorical_accuracy: 0.4808\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00005-1.55246-0.27711-1.35919-0.48077.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 18s 212ms/step - loss: 1.5912 - categorical_accuracy: 0.2530 - val_loss: 1.4278 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00006-1.59116-0.25301-1.42779-0.50000.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 17s 202ms/step - loss: 1.4999 - categorical_accuracy: 0.3414 - val_loss: 1.3435 - val_categorical_accuracy: 0.5385\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00007-1.49989-0.34137-1.34349-0.53846.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 17s 208ms/step - loss: 1.5624 - categorical_accuracy: 0.2851 - val_loss: 1.3964 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00008-1.56237-0.28514-1.39639-0.46154.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 19s 224ms/step - loss: 1.5164 - categorical_accuracy: 0.3092 - val_loss: 1.3439 - val_categorical_accuracy: 0.5385\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00009-1.51640-0.30924-1.34391-0.53846.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 17s 200ms/step - loss: 1.5164 - categorical_accuracy: 0.3213 - val_loss: 1.2908 - val_categorical_accuracy: 0.5962\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00010-1.51640-0.32129-1.29080-0.59615.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 17s 210ms/step - loss: 1.3934 - categorical_accuracy: 0.4217 - val_loss: 1.3333 - val_categorical_accuracy: 0.4808\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00011-1.39345-0.42169-1.33328-0.48077.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 17s 205ms/step - loss: 1.4229 - categorical_accuracy: 0.3655 - val_loss: 1.2869 - val_categorical_accuracy: 0.5385\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00012-1.42292-0.36546-1.28690-0.53846.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 1.4664 - categorical_accuracy: 0.3695 - val_loss: 1.2399 - val_categorical_accuracy: 0.5769\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00013-1.46644-0.36948-1.23989-0.57692.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 1.4449 - categorical_accuracy: 0.3373 - val_loss: 1.2187 - val_categorical_accuracy: 0.5385\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00014-1.44495-0.33735-1.21874-0.53846.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 17s 210ms/step - loss: 1.4531 - categorical_accuracy: 0.3815 - val_loss: 1.3132 - val_categorical_accuracy: 0.5769\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00015-1.45315-0.38153-1.31318-0.57692.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 1.4256 - categorical_accuracy: 0.3735 - val_loss: 1.2732 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00016-1.42564-0.37349-1.27319-0.46154.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 17s 208ms/step - loss: 1.3903 - categorical_accuracy: 0.4056 - val_loss: 1.2018 - val_categorical_accuracy: 0.5577\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00017-1.39025-0.40562-1.20175-0.55769.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 1.3860 - categorical_accuracy: 0.4096 - val_loss: 1.1856 - val_categorical_accuracy: 0.5962\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00018-1.38601-0.40964-1.18560-0.59615.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 17s 202ms/step - loss: 1.4153 - categorical_accuracy: 0.3454 - val_loss: 1.1186 - val_categorical_accuracy: 0.5577\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00019-1.41528-0.34538-1.11864-0.55769.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 17s 207ms/step - loss: 1.4328 - categorical_accuracy: 0.3655 - val_loss: 1.1867 - val_categorical_accuracy: 0.5385\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582batch_8/model_-00020-1.43278-0.36546-1.18669-0.53846.h5\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"4\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=2, log=\"batch_8\",filters = [16,32,64,128])\n",
    "print(\"4\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_25 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_25 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 16\n",
      "Source path =  ./Project_data/train ; batch size = 16\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/42 [===>..........................] - ETA: 52s - loss: 3.1164 - categorical_accuracy: 0.1979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 46s 1s/step - loss: 2.4277 - categorical_accuracy: 0.2374 - val_loss: 1.4290 - val_categorical_accuracy: 0.3900\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00001-2.44209-0.23680-1.42895-0.39000.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 17s 402ms/step - loss: 1.8130 - categorical_accuracy: 0.2483 - val_loss: 1.5950 - val_categorical_accuracy: 0.2143\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00002-1.81301-0.24830-1.59496-0.21429.h5\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 19s 447ms/step - loss: 1.7254 - categorical_accuracy: 0.2483 - val_loss: 1.3588 - val_categorical_accuracy: 0.4286\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00003-1.72536-0.24830-1.35881-0.42857.h5\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 16s 377ms/step - loss: 1.5103 - categorical_accuracy: 0.2695 - val_loss: 1.4788 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00004-1.51374-0.27273-1.47884-0.35714.h5\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 14s 338ms/step - loss: 1.6135 - categorical_accuracy: 0.2619 - val_loss: 1.4173 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00005-1.61349-0.26190-1.41728-0.35714.h5\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 1.6448 - categorical_accuracy: 0.2762 - val_loss: 1.4552 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00006-1.64480-0.27619-1.45518-0.35714.h5\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 12s 289ms/step - loss: 1.5248 - categorical_accuracy: 0.2996 - val_loss: 1.3693 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00007-1.54667-0.28333-1.36927-0.53571.h5\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 9s 217ms/step - loss: 1.5407 - categorical_accuracy: 0.3095 - val_loss: 1.4420 - val_categorical_accuracy: 0.3214\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00008-1.54073-0.30952-1.44203-0.32143.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 9s 212ms/step - loss: 1.5091 - categorical_accuracy: 0.2778 - val_loss: 1.4468 - val_categorical_accuracy: 0.3214\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00009-1.50912-0.27778-1.44677-0.32143.h5\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.4673 - categorical_accuracy: 0.3571 - val_loss: 1.3139 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00010-1.46728-0.35714-1.31392-0.50000.h5\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 9s 214ms/step - loss: 1.5266 - categorical_accuracy: 0.2857 - val_loss: 1.3135 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00011-1.52656-0.28571-1.31349-0.53571.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 9s 210ms/step - loss: 1.5003 - categorical_accuracy: 0.3254 - val_loss: 1.4119 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00012-1.50031-0.32540-1.41186-0.53571.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 9s 222ms/step - loss: 1.4945 - categorical_accuracy: 0.3651 - val_loss: 1.3064 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00013-1.49455-0.36508-1.30640-0.53571.h5\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 1.5080 - categorical_accuracy: 0.3810 - val_loss: 1.2606 - val_categorical_accuracy: 0.4286\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00014-1.50802-0.38095-1.26055-0.42857.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 9s 208ms/step - loss: 1.5661 - categorical_accuracy: 0.3492 - val_loss: 1.3880 - val_categorical_accuracy: 0.4286\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00015-1.56606-0.34921-1.38800-0.42857.h5\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 9s 223ms/step - loss: 1.4025 - categorical_accuracy: 0.3968 - val_loss: 1.2933 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00016-1.40254-0.39683-1.29326-0.35714.h5\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 9s 208ms/step - loss: 1.4190 - categorical_accuracy: 0.3730 - val_loss: 1.4597 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00017-1.41902-0.37302-1.45968-0.50000.h5\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 9s 211ms/step - loss: 1.3730 - categorical_accuracy: 0.4048 - val_loss: 1.3232 - val_categorical_accuracy: 0.5714\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00018-1.37302-0.40476-1.32320-0.57143.h5\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 9s 211ms/step - loss: 1.5210 - categorical_accuracy: 0.3254 - val_loss: 1.2068 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00019-1.52104-0.32540-1.20682-0.53571.h5\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.3963 - categorical_accuracy: 0.4206 - val_loss: 1.2576 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582batch_16/model_-00020-1.39626-0.42063-1.25764-0.53571.h5\n",
      "2222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"2\"*100)\n",
    "train_model(epoch=20, batch_size=16, img_norm_method=2,log=\"batch_16\",filters = [16,32,64,128])\n",
    "print(\"2\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_31 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_32 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 32\n",
      "Source path =  ./Project_data/train ; batch size = 32\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/21 [===>..........................] - ETA: 56s - loss: 3.5408 - categorical_accuracy: 0.1875 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 48s 2s/step - loss: 2.7956 - categorical_accuracy: 0.2159 - val_loss: 1.5388 - val_categorical_accuracy: 0.3100\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00001-2.81711-0.21870-1.53876-0.31000.h5\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 10s 460ms/step - loss: 1.6818 - categorical_accuracy: 0.2340 - val_loss: 1.5990 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00002-1.68181-0.23395-1.59899-0.43750.h5\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 28s 1s/step - loss: 1.7919 - categorical_accuracy: 0.2754 - val_loss: 1.6102 - val_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00003-1.79193-0.27536-1.61024-0.12500.h5\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 18s 836ms/step - loss: 1.5849 - categorical_accuracy: 0.2011 - val_loss: 1.5056 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00004-1.59941-0.20186-1.50558-0.25000.h5\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 17s 807ms/step - loss: 1.6940 - categorical_accuracy: 0.2832 - val_loss: 1.4202 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00005-1.69398-0.28321-1.42024-0.56250.h5\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 26s 1s/step - loss: 1.5284 - categorical_accuracy: 0.2984 - val_loss: 1.4514 - val_categorical_accuracy: 0.3125\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00006-1.53551-0.29873-1.45138-0.31250.h5\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 9s 419ms/step - loss: 1.6073 - categorical_accuracy: 0.2605 - val_loss: 1.4535 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00007-1.60731-0.26050-1.45353-0.25000.h5\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.6332 - categorical_accuracy: 0.2521 - val_loss: 1.5157 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00008-1.63323-0.25210-1.51567-0.43750.h5\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5639 - categorical_accuracy: 0.3081 - val_loss: 1.4666 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00009-1.56393-0.30812-1.46663-0.37500.h5\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5417 - categorical_accuracy: 0.3810 - val_loss: 1.4690 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00010-1.54168-0.38095-1.46900-0.43750.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5125 - categorical_accuracy: 0.3277 - val_loss: 1.2126 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00011-1.51246-0.32773-1.21264-0.62500.h5\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5541 - categorical_accuracy: 0.3501 - val_loss: 1.3715 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00012-1.55407-0.35014-1.37148-0.43750.h5\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.4782 - categorical_accuracy: 0.3221 - val_loss: 1.3705 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00013-1.47816-0.32213-1.37053-0.56250.h5\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.4881 - categorical_accuracy: 0.3585 - val_loss: 1.3796 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00014-1.48813-0.35854-1.37963-0.56250.h5\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 24s 1s/step - loss: 1.5182 - categorical_accuracy: 0.3081 - val_loss: 1.4135 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00015-1.51817-0.30812-1.41354-0.50000.h5\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.4809 - categorical_accuracy: 0.3305 - val_loss: 1.3799 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00016-1.48094-0.33053-1.37988-0.56250.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.4997 - categorical_accuracy: 0.3697 - val_loss: 1.2787 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00017-1.49973-0.36975-1.27872-0.50000.h5\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.4816 - categorical_accuracy: 0.3613 - val_loss: 1.3469 - val_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00018-1.48157-0.36134-1.34686-0.43750.h5\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 25s 1s/step - loss: 1.4750 - categorical_accuracy: 0.3725 - val_loss: 1.3990 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00019-1.47502-0.37255-1.39896-0.25000.h5\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.4574 - categorical_accuracy: 0.3669 - val_loss: 1.4381 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582batch_32/model_-00020-1.45741-0.36695-1.43813-0.37500.h5\n",
      "3333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"3\"*100)\n",
    "train_model(epoch=20, batch_size=32, img_norm_method=2,log=\"batch_32\",filters = [16,32,64,128])\n",
    "print(\"3\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_33 (Conv3D)           (None, 18, 100, 100, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 18, 100, 100, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 18, 100, 100, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_33 (MaxPooling (None, 9, 50, 50, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_34 (Conv3D)           (None, 9, 50, 50, 16)     3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 50, 50, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_34 (MaxPooling (None, 4, 25, 25, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_35 (Conv3D)           (None, 4, 25, 25, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 4, 25, 25, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_35 (MaxPooling (None, 2, 12, 12, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_36 (Conv3D)           (None, 2, 12, 12, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 2, 12, 12, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_36 (MaxPooling (None, 1, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               590080    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 651,365\n",
      "Trainable params: 651,125\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n",
      "./Project_data/val ; batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 0s - loss: 3.4421 - categorical_accuracy: 0.1677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 49s 591ms/step - loss: 3.4161 - categorical_accuracy: 0.1674 - val_loss: 1.7400 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00001-3.41930-0.16742-1.74003-0.26000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 35s 425ms/step - loss: 2.7837 - categorical_accuracy: 0.1842 - val_loss: 1.5566 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00002-2.78374-0.18417-1.55664-0.38462.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 30s 362ms/step - loss: 2.6757 - categorical_accuracy: 0.2062 - val_loss: 1.6435 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00003-2.67434-0.20713-1.64345-0.23077.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 26s 312ms/step - loss: 2.4929 - categorical_accuracy: 0.1847 - val_loss: 1.6994 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00004-2.48071-0.18414-1.69937-0.28846.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 2.1672 - categorical_accuracy: 0.2610 - val_loss: 1.5382 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00005-2.16725-0.26104-1.53822-0.25000.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 17s 210ms/step - loss: 2.0392 - categorical_accuracy: 0.2651 - val_loss: 1.6055 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00006-2.03925-0.26506-1.60550-0.28846.h5\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 17s 209ms/step - loss: 2.2527 - categorical_accuracy: 0.1968 - val_loss: 1.6206 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00007-2.25274-0.19679-1.62061-0.34615.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 2.0885 - categorical_accuracy: 0.2088 - val_loss: 1.6353 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00008-2.08846-0.20884-1.63528-0.30769.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 18s 218ms/step - loss: 2.1312 - categorical_accuracy: 0.2450 - val_loss: 1.5701 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00009-2.13115-0.24498-1.57009-0.32692.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 17s 209ms/step - loss: 2.1676 - categorical_accuracy: 0.2048 - val_loss: 1.5349 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00010-2.16758-0.20482-1.53486-0.34615.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 1.8742 - categorical_accuracy: 0.2450 - val_loss: 1.6157 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00011-1.87423-0.24498-1.61572-0.26923.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 18s 213ms/step - loss: 2.2194 - categorical_accuracy: 0.2048 - val_loss: 1.5623 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00012-2.21944-0.20482-1.56230-0.32692.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 18s 219ms/step - loss: 1.9366 - categorical_accuracy: 0.2731 - val_loss: 1.4898 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00013-1.93655-0.27309-1.48977-0.40385.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 18s 211ms/step - loss: 2.0943 - categorical_accuracy: 0.2088 - val_loss: 1.5329 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00014-2.09433-0.20884-1.53288-0.30769.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 17s 208ms/step - loss: 2.0791 - categorical_accuracy: 0.2129 - val_loss: 1.6049 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00015-2.07913-0.21285-1.60493-0.23077.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 1.9376 - categorical_accuracy: 0.2129 - val_loss: 1.5360 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00016-1.93759-0.21285-1.53597-0.38462.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 1.8557 - categorical_accuracy: 0.2329 - val_loss: 1.5040 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00017-1.85570-0.23293-1.50405-0.36538.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 17s 209ms/step - loss: 1.9369 - categorical_accuracy: 0.2169 - val_loss: 1.5628 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00018-1.93694-0.21687-1.56285-0.36538.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 19s 227ms/step - loss: 1.8829 - categorical_accuracy: 0.2972 - val_loss: 1.5249 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00019-1.88289-0.29719-1.52492-0.30769.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 17s 207ms/step - loss: 1.9972 - categorical_accuracy: 0.1727 - val_loss: 1.5271 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582filter_8/model_-00020-1.99717-0.17269-1.52710-0.40385.h5\n",
      "4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(\"4\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=2, log=\"filter_8\",filters=[8,16,32,64])\n",
    "print(\"4\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_37 (Conv3D)           (None, 18, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 18, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 18, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_37 (MaxPooling (None, 9, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_38 (Conv3D)           (None, 9, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 9, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_39 (Conv3D)           (None, 4, 25, 25, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_39 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_40 (Conv3D)           (None, 2, 12, 12, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,321,925\n",
      "Trainable params: 1,321,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 8\n",
      "Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/83 [============================>.] - ETA: 0s - loss: 3.2803 - categorical_accuracy: 0.1845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 47s 564ms/step - loss: 3.2533 - categorical_accuracy: 0.1857 - val_loss: 1.5885 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00001-3.25658-0.18552-1.58855-0.23000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 35s 423ms/step - loss: 2.6625 - categorical_accuracy: 0.2186 - val_loss: 1.6697 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00002-2.66246-0.21859-1.66971-0.23077.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 28s 342ms/step - loss: 2.5314 - categorical_accuracy: 0.2000 - val_loss: 1.5631 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00003-2.55844-0.19822-1.56309-0.26923.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 27s 330ms/step - loss: 2.5605 - categorical_accuracy: 0.1494 - val_loss: 1.5243 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00004-2.56587-0.15345-1.52427-0.25000.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 2.3979 - categorical_accuracy: 0.2530 - val_loss: 1.5193 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00005-2.39792-0.25301-1.51926-0.30769.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 2.3787 - categorical_accuracy: 0.2088 - val_loss: 1.5250 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00006-2.37865-0.20884-1.52497-0.28846.h5\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 18s 214ms/step - loss: 2.2439 - categorical_accuracy: 0.2450 - val_loss: 1.4846 - val_categorical_accuracy: 0.4038\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00007-2.24389-0.24498-1.48459-0.40385.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 2.2846 - categorical_accuracy: 0.2329 - val_loss: 1.4820 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00008-2.28465-0.23293-1.48205-0.32692.h5\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 19s 224ms/step - loss: 2.1658 - categorical_accuracy: 0.2651 - val_loss: 1.5011 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00009-2.16580-0.26506-1.50108-0.38462.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 2.1511 - categorical_accuracy: 0.2369 - val_loss: 1.5328 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00010-2.15108-0.23695-1.53282-0.28846.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 17s 205ms/step - loss: 2.1258 - categorical_accuracy: 0.2289 - val_loss: 1.4505 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00011-2.12583-0.22892-1.45046-0.46154.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 19s 224ms/step - loss: 1.9362 - categorical_accuracy: 0.2851 - val_loss: 1.4926 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00012-1.93622-0.28514-1.49259-0.30769.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 2.0098 - categorical_accuracy: 0.2490 - val_loss: 1.4666 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00013-2.00983-0.24900-1.46656-0.46154.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 17s 210ms/step - loss: 2.0091 - categorical_accuracy: 0.2450 - val_loss: 1.4904 - val_categorical_accuracy: 0.3077\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00014-2.00910-0.24498-1.49040-0.30769.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 18s 222ms/step - loss: 1.9491 - categorical_accuracy: 0.2169 - val_loss: 1.4432 - val_categorical_accuracy: 0.4423\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00015-1.94913-0.21687-1.44324-0.44231.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 18s 213ms/step - loss: 2.0957 - categorical_accuracy: 0.2410 - val_loss: 1.4806 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00016-2.09569-0.24096-1.48065-0.38462.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 1.9964 - categorical_accuracy: 0.2450 - val_loss: 1.4792 - val_categorical_accuracy: 0.3846\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00017-1.99644-0.24498-1.47917-0.38462.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 19s 223ms/step - loss: 1.9661 - categorical_accuracy: 0.2450 - val_loss: 1.4792 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00018-1.96606-0.24498-1.47919-0.28846.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 18s 218ms/step - loss: 1.9167 - categorical_accuracy: 0.2610 - val_loss: 1.4817 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00019-1.91669-0.26104-1.48172-0.50000.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 1.9544 - categorical_accuracy: 0.2530 - val_loss: 1.4499 - val_categorical_accuracy: 0.4615\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582filter_16/model_-00020-1.95441-0.25301-1.44991-0.46154.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "5555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555555\n"
     ]
    }
   ],
   "source": [
    "print(\"5\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=2, log=\"filter_16\",filters=[16,32,64,128])\n",
    "print(\"5\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_41 (Conv3D)           (None, 18, 100, 100, 32)  2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 18, 100, 100, 32)  128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 18, 100, 100, 32)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 9, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 9, 50, 50, 64)     55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 9, 50, 50, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 9, 50, 50, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 4, 25, 25, 128)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 4, 25, 25, 128)    512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 4, 25, 25, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 2, 12, 12, 256)    295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 2, 12, 12, 256)    1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 2, 12, 12, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling (None, 1, 6, 6, 256)      0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 6, 6, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,822,021\n",
      "Trainable params: 2,821,061\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n",
      "Source path =  ./Project_data/val ; batch size = 8\n",
      "Source path =  ./Project_data/train ; batch size = 8\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/83 [============================>.] - ETA: 1s - loss: 3.5267 - categorical_accuracy: 0.2052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 51s 620ms/step - loss: 3.4905 - categorical_accuracy: 0.2068 - val_loss: 1.6405 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00001-3.49380-0.20664-1.64048-0.23000.h5\n",
      "Epoch 2/20\n",
      "83/83 [==============================] - 37s 440ms/step - loss: 2.9577 - categorical_accuracy: 0.2014 - val_loss: 1.5970 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00002-2.95767-0.20138-1.59696-0.25000.h5\n",
      "Epoch 3/20\n",
      "83/83 [==============================] - 29s 353ms/step - loss: 2.6539 - categorical_accuracy: 0.1759 - val_loss: 1.4831 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00003-2.64970-0.17595-1.48315-0.34615.h5\n",
      "Epoch 4/20\n",
      "83/83 [==============================] - 27s 323ms/step - loss: 2.3662 - categorical_accuracy: 0.1919 - val_loss: 1.5133 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00004-2.38744-0.18670-1.51333-0.32692.h5\n",
      "Epoch 5/20\n",
      "83/83 [==============================] - 18s 216ms/step - loss: 2.3589 - categorical_accuracy: 0.2249 - val_loss: 1.5730 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00005-2.35894-0.22490-1.57301-0.23077.h5\n",
      "Epoch 6/20\n",
      "83/83 [==============================] - 18s 222ms/step - loss: 2.4125 - categorical_accuracy: 0.1928 - val_loss: 1.5191 - val_categorical_accuracy: 0.2308\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00006-2.41249-0.19277-1.51911-0.23077.h5\n",
      "Epoch 7/20\n",
      "83/83 [==============================] - 18s 217ms/step - loss: 2.2669 - categorical_accuracy: 0.2129 - val_loss: 1.5234 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00007-2.26692-0.21285-1.52345-0.32692.h5\n",
      "Epoch 8/20\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 2.4080 - categorical_accuracy: 0.1968 - val_loss: 1.5228 - val_categorical_accuracy: 0.2115\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00008-2.40799-0.19679-1.52276-0.21154.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 9/20\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 2.3098 - categorical_accuracy: 0.2450 - val_loss: 1.5042 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00009-2.30982-0.24498-1.50424-0.26923.h5\n",
      "Epoch 10/20\n",
      "83/83 [==============================] - 18s 218ms/step - loss: 2.0744 - categorical_accuracy: 0.2209 - val_loss: 1.4948 - val_categorical_accuracy: 0.2692\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00010-2.07441-0.22088-1.49479-0.26923.h5\n",
      "Epoch 11/20\n",
      "83/83 [==============================] - 18s 218ms/step - loss: 2.1448 - categorical_accuracy: 0.2249 - val_loss: 1.4976 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00011-2.14478-0.22490-1.49756-0.28846.h5\n",
      "Epoch 12/20\n",
      "83/83 [==============================] - 18s 221ms/step - loss: 2.3202 - categorical_accuracy: 0.1807 - val_loss: 1.5294 - val_categorical_accuracy: 0.2115\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00012-2.32020-0.18072-1.52943-0.21154.h5\n",
      "Epoch 13/20\n",
      "83/83 [==============================] - 19s 234ms/step - loss: 2.2074 - categorical_accuracy: 0.1888 - val_loss: 1.4774 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00013-2.20736-0.18876-1.47742-0.34615.h5\n",
      "Epoch 14/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 2.0722 - categorical_accuracy: 0.2450 - val_loss: 1.4983 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00014-2.07218-0.24498-1.49834-0.28846.h5\n",
      "Epoch 15/20\n",
      "83/83 [==============================] - 18s 211ms/step - loss: 2.2899 - categorical_accuracy: 0.1807 - val_loss: 1.5536 - val_categorical_accuracy: 0.1923\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00015-2.28987-0.18072-1.55358-0.19231.h5\n",
      "Epoch 16/20\n",
      "83/83 [==============================] - 19s 232ms/step - loss: 2.0255 - categorical_accuracy: 0.2731 - val_loss: 1.4309 - val_categorical_accuracy: 0.3654\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00016-2.02547-0.27309-1.43088-0.36538.h5\n",
      "Epoch 17/20\n",
      "83/83 [==============================] - 19s 225ms/step - loss: 2.1018 - categorical_accuracy: 0.2410 - val_loss: 1.5665 - val_categorical_accuracy: 0.2115\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00017-2.10178-0.24096-1.56648-0.21154.h5\n",
      "Epoch 18/20\n",
      "83/83 [==============================] - 18s 211ms/step - loss: 2.0759 - categorical_accuracy: 0.2369 - val_loss: 1.4311 - val_categorical_accuracy: 0.3462\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00018-2.07586-0.23695-1.43113-0.34615.h5\n",
      "Epoch 19/20\n",
      "83/83 [==============================] - 18s 215ms/step - loss: 2.0352 - categorical_accuracy: 0.2369 - val_loss: 1.5395 - val_categorical_accuracy: 0.2885\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00019-2.03519-0.23695-1.53950-0.28846.h5\n",
      "Epoch 20/20\n",
      "83/83 [==============================] - 19s 228ms/step - loss: 1.9993 - categorical_accuracy: 0.2369 - val_loss: 1.5024 - val_categorical_accuracy: 0.3269\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-09-0916_24_45.232582filter_32/model_-00020-1.99934-0.23695-1.50241-0.32692.h5\n",
      "6666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"6\"*100)\n",
    "train_model(epoch=20, batch_size=8, img_norm_method=2, log=\"filter_32\",filters=[32,64,128,256])\n",
    "print(\"6\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_idx = [0,1,2,4,6,8,10,12,14,16,18,20,22,24,26,27,28,29]\n",
    "\n",
    "# # length of video sequence, width, height, num_channels\n",
    "# input_shape=(len(image_idx), image_width, image_height, 3)\n",
    "# create_model(input_shape=input_shape, filters=[8,16,32,64,128,256], optimiser=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZiABGAC_hJ_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYXrRwg7_hKJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
